{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project comes under the curriculum of the **Data Analyst Nanodegree by Udacity**. In this project, I perform Data Wrangling and then Data Analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st phase of this project is **Data Wrangling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Data Wrangling process, we first gather the data from various sources like Databases, Web Scrapping etc. Then we assess the gathered data both manually and programmatically for quality and tidiness of the data. After assessing the data, we clean it to get a well structured and organised data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather\n",
    "For this project, I gathered the data from three different sources.\n",
    ">01. The WeRateDogs Twitter archive from a csv file downloaded manually from a link provided and loaded into the dataframe twitter_archive.\n",
    ">02. The tweet image predictions data from a link programatically using the python library requests and loaded the data into the dataframe image_predictions.\n",
    ">03. Lastly, I used Tweepy python access library to access the tweet data for the Tweet IDs. I queried the tweepy library, then I got JSON data. I wrote the JSON data to a text file. Then I extracted tweet ID, retweet count, and favorite count from the text file line by line and loaded the data into dataframe tweet_json. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess\n",
    "I first assessed the data visually and then programatically using python's pandas library. \n",
    "I used \n",
    ">01. The info() function to assess the datatypes, number of records in each column. \n",
    ">02. The isnull()funtion to look for the null values in the dataframes.\n",
    ">03. The describe() function to get the statistic summary of the dataframes.\n",
    ">04. The value_counts() function to get the number of the different values in a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through my assessments both manually and programatically, I got some quality and tidiness issues in the dataframes. The issues are the following:\n",
    "#### Quality\n",
    ">01. Some columns like  \n",
    "**in_reply_to_status_id**         (2278) \n",
    "**in_reply_to_user_id**           (2278)\n",
    "**retweeted_status_id**           (2175)\n",
    "**retweeted_status_user_id**      (2175) and \n",
    "**retweeted_status_timestamp**    (2175) have very large number of null values in them.\n",
    " It is better to drop them. \n",
    ">02. Column **timestamp**, **rating_denominator** and **rating_numerator** have incorrect datatypes. \n",
    ">03. Sources are not mentioned properly in the **source** column. \n",
    ">04. A lot of dog names are like \"None\" and \"a\". These aren't the names of dogs in real life, usually.\n",
    ">05. The **rating_denominator** and **rating_numerator** columns have some invalid values. \n",
    ">06. We can extract the gender of the dog from the **text** column.\n",
    ">07. Replace underscores from the dog breeds given in the columns **p1**, **p2**, **p3** in image_predictions table. \n",
    ">08. **tweet_id** in all the three dataframes is in int data type. It is better that it should be in string datatype. \n",
    ">09. tweet_json dataframe has 20 duplicate rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness \n",
    ">01. Keep only the true prediction column about the dogs instead of every prediction column.\n",
    ">02. Combine each dog stage column into one column.\n",
    ">03. The **rating_denominator** and **rating_numerator** columns can be converted into a single **rating** column.\n",
    ">04. All the three dataframes can be merged into a single dataframe **df_clean**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of Cleaning contains 3 steps-\n",
    ">01. **Define**: In this step we define the issue related to the data and how we are going to deal with it using the code.\n",
    ">02. **Code**: In this step we enter the code to resolve the issue defined earlier.\n",
    ">03. **Test**: In this step we test whether the code we entered has resolved the issue or not. \n",
    "\n",
    "For the Cleaning purpose I ,generally, used some assessment functions like info(), value_counts() and some Pandas Library functions drop(), merge(), apply() etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2st phase of this project is **Data Analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Cleaning part of Data Wrangling, I analyzed the clean dataframe. Through my analysis I tried to find the answer of the following questions:\n",
    ">01. Which tweet ID has the maximum retweet count?\n",
    ">02. Which tweet ID has the maximum favorite count or likes?\n",
    ">03. Which is the most frequent source for tweeting?\n",
    ">04. Which is the popular gender of dogs?\n",
    ">05. Tweet ID associated with highest ratings.\n",
    ">06. Which is the most frequently adopted breed of dogs?\n",
    ">07. Which names do most people like to have for their dogs?\n",
    "\n",
    "To understand the analysis in a better way, I plotted the graphs using Python's Seaborn library, Matplotlib library and plot() function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
